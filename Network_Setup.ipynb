{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "125fe860-2880-4694-b852-5495986a4f77",
   "metadata": {},
   "source": [
    "# Setting Up Network\n",
    "\n",
    "## Assigning a reference location and random weights\n",
    "\n",
    "This script generates randomized weight distributions (`wt_1000` to `wt_6000`) for 300 active zones (excluding 100 zero-weight zones), capped at 25 lbs each, and saves them in `Centroids.csv`. A fixed access point (ID 9999) is added. Randomization ensures varied but controlled loads per scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1345c98c-ecc2-4dd2-b460-a67cab2625c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dbfread import DBF\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# loading centroids\n",
    "centroids_dbf = DBF(\"Centroids.dbf\")\n",
    "centroids_df = pd.DataFrame(iter(centroids_dbf))\n",
    "\n",
    "# Add reference centroid (access point) with ID 9999\n",
    "ref = pd.DataFrame([{'cid': 9999, 'x': 500, 'y': 400}])\n",
    "centroids_df = pd.concat([centroids_df, ref], ignore_index=True)\n",
    "\n",
    "def assign_random_weights(df, total_weight):\n",
    "    np.random.seed()  # new random draw each run\n",
    "    weight_col = f'wt_{total_weight}'\n",
    "    df[weight_col] = 0.0\n",
    "\n",
    "    # Eligible nodes (exclude depot)\n",
    "    valid_idx = df[df['cid'] != 9999].index\n",
    "\n",
    "    # Pick 100 zones with zero weight\n",
    "    zero_idx = np.random.choice(valid_idx, 100, replace=False)\n",
    "    active_idx = valid_idx.difference(zero_idx)\n",
    "\n",
    "    # Assign initial random weights (1â€“25)\n",
    "    weights = np.random.randint(1, 26, size=len(active_idx)).astype(float)\n",
    "\n",
    "    # Scale iteratively to match total_weight (without exceeding 25)\n",
    "    while abs(weights.sum() - total_weight) > 0.01:\n",
    "        diff = total_weight - weights.sum()\n",
    "        if diff > 0:\n",
    "            # Need to add weight\n",
    "            idx = np.random.choice(len(weights))\n",
    "            if weights[idx] < 25:\n",
    "                add = min(diff, 25 - weights[idx], 1)  # add at most 1 lb per step\n",
    "                weights[idx] += add\n",
    "        elif diff < 0:\n",
    "            # Need to subtract weight\n",
    "            idx = np.random.choice(len(weights))\n",
    "            if weights[idx] > 1:\n",
    "                sub = min(-diff, weights[idx] - 1, 1)  # subtract at most 1 lb per step\n",
    "                weights[idx] -= sub\n",
    "\n",
    "    # Assign final weights back\n",
    "    df.loc[active_idx, weight_col] = weights\n",
    "    df.loc[df['cid'] == 9999, weight_col] = 0\n",
    "    return df\n",
    "\n",
    "# Run for multiple caps\n",
    "for w in [1000, 2000, 3000, 4000, 5000, 6000]:\n",
    "    centroids_df = assign_random_weights(centroids_df, w)\n",
    "\n",
    "# Save to CSV\n",
    "centroids_df.to_csv(\"Centroids.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1246f2-7bc2-4b71-bcfd-d35e2033bdfb",
   "metadata": {},
   "source": [
    "## Generating Filtered Link Networks for Each Weight Scenario\n",
    "\n",
    "This script filters the full link network (`Drone_Links_AllToAll.csv`) for each weight scenario (`wt_1000` to `wt_6000`) by retaining only the 20 nearest neighbors per active node and all depot-related links. It ensures bidirectionality and assigns unique IDs to depot edges. Outputs are saved as `Drone_Links_Filtered_*.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34273d32-8609-4730-9ab1-1ee41fe01d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Drone_Links_Filtered_1000.csv with 12180 bidirectional edges for 300 active nodes (k=20). Depot links assigned IDs starting at 200001.\n",
      "Saved Drone_Links_Filtered_2000.csv with 12180 bidirectional edges for 300 active nodes (k=20). Depot links assigned IDs starting at 200001.\n",
      "Saved Drone_Links_Filtered_3000.csv with 12180 bidirectional edges for 300 active nodes (k=20). Depot links assigned IDs starting at 200001.\n",
      "Saved Drone_Links_Filtered_4000.csv with 12180 bidirectional edges for 300 active nodes (k=20). Depot links assigned IDs starting at 200001.\n",
      "Saved Drone_Links_Filtered_5000.csv with 12180 bidirectional edges for 300 active nodes (k=20). Depot links assigned IDs starting at 200001.\n",
      "Saved Drone_Links_Filtered_6000.csv with 12180 bidirectional edges for 300 active nodes (k=20). Depot links assigned IDs starting at 200001.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load centroids and links\n",
    "centroids_df = pd.read_csv(\"Centroids.csv\")\n",
    "links_df = pd.read_csv(\"Drone_Links_AllToAll.csv\")\n",
    "\n",
    "# Weight scenarios\n",
    "weight_columns = [\"wt_1000\", \"wt_2000\", \"wt_3000\", \"wt_4000\", \"wt_5000\", \"wt_6000\"]\n",
    "k_neighbors = 20  # number of nearest neighbors per node\n",
    "\n",
    "for wcol in weight_columns:\n",
    "    # Active nodes (non-zero weight) + depot\n",
    "    weights = dict(zip(centroids_df['cid'], centroids_df[wcol] * 0.453592))\n",
    "    active_nodes = [cid for cid, w in weights.items() if w > 0.0]\n",
    "    nodes = active_nodes + [9999]  # include depot\n",
    "\n",
    "    # Filter links to just these nodes\n",
    "    sublinks = links_df[(links_df['from_id'].isin(nodes)) & (links_df['to_id'].isin(nodes))]\n",
    "\n",
    "    # For each node, find up to 20 nearest neighbors (excluding depot)\n",
    "    filtered_rows = []\n",
    "    for node in active_nodes:\n",
    "        nbrs = sublinks[(sublinks['from_id'] == node) & (sublinks['to_id'].isin(active_nodes))]\n",
    "        nbrs = nbrs.sort_values('length').head(k_neighbors)\n",
    "        filtered_rows.append(nbrs)\n",
    "\n",
    "    # Combine all selected neighbor edges\n",
    "    filtered_df = pd.concat(filtered_rows, ignore_index=True)\n",
    "\n",
    "    # --- Make the network bidirectional ---\n",
    "    # For every (a,b), ensure (b,a) is present\n",
    "    reverse_edges = filtered_df.rename(columns={'from_id': 'to_id', 'to_id': 'from_id'}).copy()\n",
    "    # Merge original and reverse edges\n",
    "    filtered_df = pd.concat([filtered_df, reverse_edges], ignore_index=True)\n",
    "    # Drop duplicates (same direction pairs kept only once)\n",
    "    filtered_df.drop_duplicates(subset=['from_id', 'to_id'], inplace=True)\n",
    "\n",
    "    # Always keep depot edges (both directions) from sublinks\n",
    "    depot_links = sublinks[(sublinks['from_id'] == 9999) | (sublinks['to_id'] == 9999)]\n",
    "    filtered_df = pd.concat([filtered_df, depot_links], ignore_index=True)\n",
    "    filtered_df.drop_duplicates(subset=['from_id', 'to_id'], inplace=True)\n",
    "\n",
    "    # --- Assign unique IDs for depot-related links (starting at 200001) ---\n",
    "    max_existing_id = links_df['id'].max() if 'id' in links_df.columns else 0\n",
    "    next_id = max(200001, max_existing_id + 1)\n",
    "\n",
    "    depot_mask = (filtered_df['from_id'] == 9999) | (filtered_df['to_id'] == 9999)\n",
    "    depot_count = depot_mask.sum()\n",
    "    new_ids = range(next_id, next_id + depot_count)\n",
    "    filtered_df.loc[depot_mask, 'id'] = new_ids\n",
    "\n",
    "    # Save filtered dataset\n",
    "    out_file = f\"Drone_Links_Filtered_{wcol.split('_')[1]}.csv\"\n",
    "    filtered_df.to_csv(out_file, index=False)\n",
    "    print(f\"Saved {out_file} with {len(filtered_df)} bidirectional edges \"\n",
    "          f\"for {len(active_nodes)} active nodes (k={k_neighbors}). \"\n",
    "          f\"Depot links assigned IDs starting at {next_id}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d239aabd-a07b-4ca1-990c-56d6789ab98c",
   "metadata": {},
   "source": [
    "## Adding Depot Links to the Truck Network\n",
    "\n",
    "This script loads `Grid_Lines_Melted_v2.dbf`, appends four custom links to connect the depot (ID 9999) to the network, and saves the updated truck path dataset as `Grid_Lines_Melted.csv`. These links ensure connectivity for depot access in routing models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3efdd3e6-6628-4149-b0f5-7c3cc61671eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dbfread import DBF\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# loading centroids\n",
    "truck_dbf = DBF(\"Grid_Lines_Melted_v2.dbf\")\n",
    "truck_df = pd.DataFrame(iter(truck_dbf))\n",
    "\n",
    "#Adding the two links between depot and network edge\n",
    "link_1 = pd.DataFrame([{'line_id': 9999, 'x1': 400, 'y1': 400, 'x2': 500, 'y2': 400, 'Truck_Path': 1, 'length': 100, 'cid': 9999, 'int_line_i': 419}])\n",
    "link_2 = pd.DataFrame([{'line_id': 9999, 'x1': 400, 'y1': 400, 'x2': 500, 'y2': 400, 'Truck_Path': 1, 'length': 100, 'cid': 9999, 'int_line_i': 839}])\n",
    "link_3 = pd.DataFrame([{'line_id': 419, 'x1': 380, 'y1': 400, 'x2': 400, 'y2': 400, 'Truck_Path': 1, 'length': 20, 'cid': 399, 'int_line_i': 9999}])\n",
    "link_4 = pd.DataFrame([{'line_id': 839, 'x1': 400, 'y1': 380, 'x2': 400, 'y2': 400, 'Truck_Path': 1, 'length': 20, 'cid': 399, 'int_line_i': 9999}])\n",
    "truck_df = pd.concat([truck_df, link_1, link_2, link_3, link_4], ignore_index=True)\n",
    "\n",
    "# Save to CSV\n",
    "truck_df.to_csv(\"Grid_Lines_Melted.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
